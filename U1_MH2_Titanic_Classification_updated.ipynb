{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nkatara/iiit-ai-ml/blob/main/U1_MH2_Titanic_Classification_updated.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x3A2XBqYQg-N"
      },
      "source": [
        "# Advanced Certification in AIML\n",
        "## A Program by IIIT-H and TalentSprint\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jw4QHJlfsSF4"
      },
      "source": [
        "## Learning Objectives\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "At the end of the mini-hackathon you will be able to:\n",
        "* Perform Data preprocessing\n",
        "* Apply different ML algorithms on the **Titanic** dataset\n",
        "* Perform VotingClassifier\n"
      ],
      "metadata": {
        "id": "EsSB95vPsoxS"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nh70dVHx0G_B"
      },
      "source": [
        "## Dataset Description"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-GMJTRb0Iyy"
      },
      "source": [
        "The sinking of the Titanic is one of the most infamous shipwrecks in history.\n",
        "\n",
        "On April 15, 1912, during her maiden voyage, the widely considered “unsinkable” RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren’t enough lifeboats for everyone onboard, resulting in the death of many passengers and crew.\n",
        "\n",
        "While there was some element of luck involved in surviving, it seems some groups of people were more likely to survive than others.\n",
        "\n",
        "[ Data Set Link: Kaggle competition](https://www.kaggle.com/competitions/titanic)\n",
        "\n",
        "<br/>\n",
        "\n",
        "### Data Set Characteristics:\n",
        "\n",
        "**PassengerId:** Id of the Passenger\n",
        "\n",
        "**Survived:** Survived or Not information\n",
        "\n",
        "**Pclass:** Socio-economic status (SES)\n",
        "  * 1st = Upper\n",
        "  * 2nd = Middle\n",
        "  * 3rd = Lower\n",
        "\n",
        "**Name:** Surname, First Names of the Passenger\n",
        "\n",
        "**Sex:** Gender of the Passenger\n",
        "\n",
        "**Age:** Age of the Passenger\n",
        "\n",
        "**SibSp:**\tNo. of siblings/spouse of the passenger aboard the Titanic\n",
        "\n",
        "**Parch:**\tNo. of parents/children of the passenger aboard the Titanic\n",
        "\n",
        "**Ticket:**\tTicket number\n",
        "\n",
        "**Fare:** Passenger fare\n",
        "\n",
        "**Cabin:**\tCabin number\n",
        "\n",
        "**Embarked:** Port of Embarkation\n",
        "  * S = Southampton\n",
        "  * C = Cherbourg\n",
        "  * Q = Queenstown\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problem Statement\n",
        "\n",
        "Build a predictive model that answers the question: “what sort of people were more likely to survive?” using titanic's passenger data (ie name, age, gender, socio-economic class, etc)."
      ],
      "metadata": {
        "id": "KmusUbENKSEt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Download the datasets\n",
        "from IPython import get_ipython\n",
        "\n",
        "ipython = get_ipython()\n",
        "\n",
        "notebook=\"U1_MH1_Data_Munging\" #name of the notebook\n",
        "\n",
        "def setup():\n",
        "    from IPython.display import HTML, display\n",
        "    ipython.magic(\"sx wget https://cdn.iiith.talentsprint.com/aiml/Experiment_related_data/titanic.csv\")\n",
        "    ipython.magic(\"sx wget https://cdn.iiith.talentsprint.com/aiml/Experiment_related_data/test_titanic.csv\")\n",
        "    print(\"Data downloaded successfully\")\n",
        "    return\n",
        "\n",
        "setup()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "ViFc50xKK-tY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "RM8x-pMDLQuq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g5fBLdQaJtd4"
      },
      "source": [
        "## Exercise 1 - Load and Explore the Data (2 Marks)\n",
        "\n",
        "* Understand different features in the training dataset\n",
        "* Understand the data types of each column\n",
        "* Notice the columns of missing values\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gn6HQH7abkyL"
      },
      "source": [
        "#### Import Required Packages"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "4tUzpuurwCyH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sW9DMblWkhj_"
      },
      "source": [
        "# Load the dataset\n",
        "df = pd.read_csv(\"titanic.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54ktmr8lh8AS"
      },
      "source": [
        "# Getting information about the dataset\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()\n"
      ],
      "metadata": {
        "id": "zAvxH5MUPWDj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "9A30oH13z1Gh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 02: Split the data into train and test sets (1 Mark)\n",
        "Note: Apply all your data preprocessing steps in the train set first and keep the test set aside."
      ],
      "metadata": {
        "id": "eQGya6YLOku-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split BEFORE preprocessing\n",
        "train_df, test_df = train_test_split(df, test_size=0.3, random_state=42)\n",
        "\n",
        "print(train_df.shape)\n",
        "print(test_df.shape)\n"
      ],
      "metadata": {
        "id": "mps-O7zbPPcL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Handle missing values\n",
        "train_df['Age'].fillna(train_df['Age'].median(), inplace=True)\n",
        "train_df['Embarked'].fillna(train_df['Embarked'].mode()[0], inplace=True)"
      ],
      "metadata": {
        "id": "1I7m-Z4A0USY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-pMXWDyaspe3"
      },
      "source": [
        "## Exercise 03: Data Cleaning and Processing (15 Marks)\n",
        "### 3.1 Working on the \"Cabin\" column (2 Marks)\n",
        "Find unique entries in the Cabin column. We can label all passengers in two categories having a cabin or not. Check the data type(use: type) of each entry of the Cabin. Convert a string data type into '1' i.e. passengers with cabin and others into '0' i.e. passengers without cabin.  Write a function for the above operation and apply it to the cabin column and create another column with the name \" Has_cabin\" containing only 0 or 1 entries.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Find Unique Entries in the Cabin Column\n",
        "df['Cabin'].unique()"
      ],
      "metadata": {
        "id": "KozjEOo9VS3Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the Data Type of Each Entry\n",
        "df['Cabin'].apply(type).unique()"
      ],
      "metadata": {
        "id": "n9N82uXWWf81"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Write a Function to Convert Cabin → 1 or 0\n",
        "def cabin_to_binary(value):\n",
        "  if isinstance(value, str):\n",
        "    return 1\n",
        "  else:\n",
        "    return 0"
      ],
      "metadata": {
        "id": "cEdx4XCu16IE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply the Function and Create \"Has_cabin\" Column\n",
        "# 1:passenger has a cabin(string)\n",
        "# 0:passenger does NOT have a cabin(NaN)\n",
        "df['Has_cabin'] = df['Cabin'].apply(cabin_to_binary)\n",
        "df[['Cabin', 'Has_cabin']].head()"
      ],
      "metadata": {
        "id": "EWFF-BGK2QWh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " ### 3.2 Working on \"SibSp\" & \"Parch\" columns (1 Mark)\n",
        "Combine columns \"SibSp\" & \"Parch\" and create another column that represents the total passengers in one ticket with the name \"family_size\". In each ticket, there might be Siblings/Spouses (SibSp =Number of Siblings/Spouses Aboard) or Parents/Children (Parch=Number of Parents/Children Aboard ) along with the passenger who booked the ticket.\n",
        "\n",
        "  "
      ],
      "metadata": {
        "id": "mUm20kyHVTZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create column family_size\n",
        "#family_size = SibSp + Parch + 1\n",
        "df['family_size'] = df['SibSp'] + df['Parch'] + 1\n"
      ],
      "metadata": {
        "id": "n2vHu13tWJx-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#nspect the new column\n",
        "df[['SibSp', 'Parch', 'family_size']].head()"
      ],
      "metadata": {
        "id": "lEkyLqqEVX2p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.3 Working on the\"Embarked\" column (2 Marks)\n",
        "The \"embarked\" column represents the port of Embarkation: Cherbourg(C), Queenstown(Q), and  Southampton(S ). Thus, the entries are of three categories in this column. Fill in the missing rows in this column. We can fill it with the most frequent category. Map these categorical string entries into numerical.\n",
        "\n"
      ],
      "metadata": {
        "id": "cGPgnKttVYRL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check unique values in \"Embarked\"\n",
        "df['Embarked'].unique()"
      ],
      "metadata": {
        "id": "IApw-rL1Y1jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Find the most frequent (mode) value\n",
        "mode_embarked = df['Embarked'].mode()[0]\n",
        "mode_embarked"
      ],
      "metadata": {
        "id": "rVTiJ27OVbzB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill missing values with the most frequent category\n",
        "df['Embarked'].fillna(df['Embarked'].mode()[0], inplace=True)"
      ],
      "metadata": {
        "id": "0TFv47f9Y0yO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Map categorical values to numerical values\n",
        "embarked_mapping = {'S': 0, 'C': 1, 'Q': 2}\n",
        "df['Embarked'] = df['Embarked'].map(embarked_mapping)\n",
        "df['Embarked'].head()\n",
        "print(embarked_mapping)\n",
        "print(df['Embarked'])"
      ],
      "metadata": {
        "id": "fVOcd37L575T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.4 Working on the \"Age\" column (2 Marks)\n",
        "find the number of NaN entries in the age column and their row index. Calculate the mean, Standard deviation of the Age column and check the distribution of the age column.We can fill the missing values with randomly generated integer values between (mean+Standard deviation, mean-Standard deviation). Use : np.isnan; np.random.randint; concept of slicing dataframe. Convert the age column as an integer data type.\n",
        "\n"
      ],
      "metadata": {
        "id": "dWmjUnN3VcF6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the number of NaN entries in the Age column\n",
        "df['Age'].isnull().sum()"
      ],
      "metadata": {
        "id": "gbLqDB1hVf1a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the row indices of NaN Age values\n",
        "nan_age_index = df[df['Age'].isnull()].index\n",
        "nan_age_index"
      ],
      "metadata": {
        "id": "MFrug-3VakhY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate mean and standard deviation of Age\n",
        "age_mean = df['Age'].mean()\n",
        "age_std  = df['Age'].std()\n",
        "\n",
        "print(\"Mean Age:\", age_mean)\n",
        "print(\"Std Age:\", age_std)\n"
      ],
      "metadata": {
        "id": "a9a69SMpa6aG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the distribution of Age\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sns.histplot(df['Age'], kde=True)\n",
        "plt.title(\"Age Distribution\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "8_YovA5O7j-H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill missing Age values with random integers\n",
        "low  = int(age_mean - age_std) # Compute the range\n",
        "high = int(age_mean + age_std) # Compute the range\n",
        "random_ages = np.random.randint(low, high, size=df['Age'].isnull().sum()) # Generate random integers for missing values\n",
        "df.loc[df['Age'].isnull(), 'Age'] = random_ages # Replace NaN values using slicing\n",
        "df['Age'] = df['Age'].astype(int) # Convert Age column to integer type\n",
        "df['Age'].isnull().sum() # check for any NAN"
      ],
      "metadata": {
        "id": "jKc2G9yg7rrS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.5 Working on \"sex\" column (1 Mark)\n",
        "Map the Sex column as 'female' : 0, 'male': 1, and convert it into an integer data type.\n",
        "\n"
      ],
      "metadata": {
        "id": "doeanDr0VgGV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['Sex'] = df['Sex'].astype('object')\n",
        "df['Sex'].replace(['nan', 'None', '', ' '], np.nan, inplace=True)\n",
        "df['Sex'].fillna(df['Sex'].mode()[0], inplace=True)\n",
        "df['Sex'] = df['Sex'].map({'female': 0, 'male': 1})\n",
        "#df['Sex'] = df['Sex'].astype(int)"
      ],
      "metadata": {
        "id": "dGN92EsEVlTQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.6  Optional- Working on the \"Name\" column :\n",
        "Fetch titles from the name. We can map these titles with numbers and convert them into an integer. Use: concept of the regular expression.\n",
        "\n",
        "### 3.7 Optional- Working on the \"Fare\" column :\n",
        "We can convert face into categorical entries like Low, Medium, and High.\n",
        "\n"
      ],
      "metadata": {
        "id": "__CWnlGhVln2"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vuuDE0mQVo7v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.8 Drop the columns (1 Mark)\n",
        "\n",
        "Drop the columns: - \"PassengerId\", \"Name\",  \"SibSp\" & \"Parch\", \"Tickets\", \"Cabin\"\n",
        "\n",
        "Now apply different ML algorithms and check the accuracy of your model.\n",
        "\n"
      ],
      "metadata": {
        "id": "6oJI0bQOVpP4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(columns=['PassengerId', 'Name', 'SibSp', 'Parch', 'Ticket', 'Cabin'], inplace=True)\n"
      ],
      "metadata": {
        "id": "1ZlnDtiiVvif"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Split Features and Target\n",
        "X = df.drop('Survived', axis=1)\n",
        "y = df['Survived']\n"
      ],
      "metadata": {
        "id": "CZW6E_HfCe02"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Train/Test Split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "X_train"
      ],
      "metadata": {
        "id": "YVYnt5p7ccKK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Helper function to evaluate models\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def evaluate_model(model):\n",
        "    model.fit(X_train, y_train)\n",
        "    preds = model.predict(X_test)\n",
        "    return accuracy_score(y_test, preds)\n"
      ],
      "metadata": {
        "id": "jp7WpWZqCkJL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Logistic Regression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "log_reg = LogisticRegression(max_iter=1000)\n",
        "acc_log = evaluate_model(log_reg)\n",
        "\n",
        "acc_log\n"
      ],
      "metadata": {
        "id": "jx9f1v7TCmsX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Decision Tree\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "dt = DecisionTreeClassifier(random_state=42)\n",
        "acc_dt = evaluate_model(dt)\n",
        "acc_dt"
      ],
      "metadata": {
        "id": "QBgU5MJSCwRM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Random Forest\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rf = RandomForestClassifier(n_estimators=200, random_state=42)\n",
        "acc_rf = evaluate_model(rf)\n",
        "acc_rf"
      ],
      "metadata": {
        "id": "op_SOWcKCzn5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#K-Nearest Neighbors\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "knn = KNeighborsClassifier(n_neighbors=7)\n",
        "acc_knn = evaluate_model(knn)\n",
        "acc_knn"
      ],
      "metadata": {
        "id": "Vwq907SWC4wn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Support Vector Machine\n",
        "from sklearn.svm import SVC\n",
        "svm = SVC(kernel='rbf')\n",
        "acc_svm = evaluate_model(svm)\n",
        "acc_svm"
      ],
      "metadata": {
        "id": "NsSHYBouC85R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.9 Apply Standard Scalar (1 Mark)"
      ],
      "metadata": {
        "id": "S2EfoVojebWn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "X_train_scaled = scaler.transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n"
      ],
      "metadata": {
        "id": "fVWd4PEaeiod"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.10 Create a single function for preprocessing the test set (X_test) and apply it. (4 Marks)\n",
        "#### **Note**: All the pre-processing steps that were applied on the train set before ML Modelling are also applied on the test set before passing through the predict function."
      ],
      "metadata": {
        "id": "Kwa6Ua9Qgbi7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_test_set(X_test, age_mean, age_std, embarked_mode, sex_mode, scaler):\n",
        "\n",
        "    X_test = X_test.copy()\n",
        "\n",
        "    # 1. Has_cabin (safe)\n",
        "    if 'Cabin' in X_test.columns:\n",
        "        X_test['Has_cabin'] = X_test['Cabin'].apply(lambda x: 1 if isinstance(x, str) else 0)\n",
        "    else:\n",
        "        X_test['Has_cabin'] = 0\n",
        "\n",
        "    # 2. family_size\n",
        "    if 'SibSp' in X_test.columns and 'Parch' in X_test.columns:\n",
        "        X_test['family_size'] = X_test['SibSp'] + X_test['Parch'] + 1\n",
        "    else:\n",
        "        X_test['family_size'] = 1\n",
        "\n",
        "    # 3. Embarked\n",
        "    X_test['Embarked'].fillna(embarked_mode, inplace=True)\n",
        "    embarked_mapping = {'S': 0, 'C': 1, 'Q': 2}\n",
        "    X_test['Embarked'] = X_test['Embarked'].map(embarked_mapping)\n",
        "\n",
        "    # 4. Sex\n",
        "    X_test['Sex'] = X_test['Sex'].astype('object')\n",
        "    X_test['Sex'].replace(['nan', 'None', '', ' '], sex_mode, inplace=True)\n",
        "    X_test['Sex'].fillna(sex_mode, inplace=True)\n",
        "    X_test['Sex'] = X_test['Sex'].map({'female': 0, 'male': 1})\n",
        "\n",
        "    # 5. Age\n",
        "    low = int(age_mean - age_std)\n",
        "    high = int(age_mean + age_std)\n",
        "    missing_age_count = X_test['Age'].isnull().sum()\n",
        "    random_ages = np.random.randint(low, high, missing_age_count)\n",
        "    X_test.loc[X_test['Age'].isnull(), 'Age'] = random_ages\n",
        "    X_test['Age'] = X_test['Age'].astype(int)\n",
        "\n",
        "    # 6. Drop unused columns (only drop if they exist)\n",
        "    cols_to_drop = ['PassengerId', 'Name', 'SibSp', 'Parch', 'Ticket', 'Cabin']\n",
        "    for col in cols_to_drop:\n",
        "        if col in X_test.columns:\n",
        "            X_test.drop(columns=col, inplace=True)\n",
        "\n",
        "    # 7. Scale\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    return X_test_scaled\n"
      ],
      "metadata": {
        "id": "RLFNNM0SgqZ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Applyting above function\n",
        "age_mean = X_train['Age'].mean()\n",
        "age_std  = X_train['Age'].std()\n",
        "embarked_mode = X_train['Embarked'].mode()[0]\n",
        "sex_mode = X_train['Sex'].mode()[0]\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)   # fit ONLY on training data\n",
        "\n"
      ],
      "metadata": {
        "id": "urGx3SRcc0kN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_processed = preprocess_test_set( X_test, age_mean, age_std, embarked_mode, sex_mode, scaler )\n"
      ],
      "metadata": {
        "id": "992tP6zQFA2q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.11 Apply standard Scalar transformation to x_test (1 Mark)"
      ],
      "metadata": {
        "id": "jlA3Gnmrc039"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)   # fit ONLY on training data\n"
      ],
      "metadata": {
        "id": "N0SAb9ccc2Qm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "0Ji2ewjTFhz7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise  4. Apply Multiple ML Algo. along with  Ensemble Technique (Voting classifier) and display the accuracy (7 Marks)\n",
        "#### Expected Accuracy >= 80%  \n"
      ],
      "metadata": {
        "id": "zUMFQj-Gc1BO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n"
      ],
      "metadata": {
        "id": "Xd-21QgEc2TV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "log_reg = LogisticRegression(max_iter=1000)\n",
        "dt = DecisionTreeClassifier(random_state=42)\n",
        "rf = RandomForestClassifier(n_estimators=200, random_state=42)\n",
        "knn = KNeighborsClassifier(n_neighbors=7)\n",
        "svm = SVC(kernel='rbf', probability=True)\n"
      ],
      "metadata": {
        "id": "t_Duj7FSF21_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models = {\n",
        "    \"Logistic Regression\": log_reg,\n",
        "    \"Decision Tree\": dt,\n",
        "    \"Random Forest\": rf,\n",
        "    \"KNN\": knn,\n",
        "    \"SVM\": svm\n",
        "}\n",
        "\n",
        "accuracies = {}\n",
        "\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train_scaled, y_train)\n",
        "    preds = model.predict(X_test_scaled)\n",
        "    accuracies[name] = accuracy_score(y_test, preds)\n"
      ],
      "metadata": {
        "id": "0BxHHMgWF8fx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "voting_clf = VotingClassifier(\n",
        "    estimators=[\n",
        "        ('lr', log_reg),\n",
        "        ('rf', rf),\n",
        "        ('svm', svm)\n",
        "    ],\n",
        "    voting='soft'\n",
        ")\n",
        "\n",
        "voting_clf.fit(X_train_scaled, y_train)\n",
        "voting_preds = voting_clf.predict(X_test_scaled)\n",
        "accuracies[\"Voting Classifier\"] = accuracy_score(y_test, voting_preds)\n"
      ],
      "metadata": {
        "id": "N4zI8whBGDR3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for model_name, acc in accuracies.items():\n",
        "    print(f\"{model_name}: {acc*100:.2f}%\")\n"
      ],
      "metadata": {
        "id": "QSKAU6N1GKn6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise  5. Pre-process the test_set (3 Marks)\n",
        "Again we have to apply the same preprocess function and standard scaler on this test set before passing through predict function.\n",
        "\n",
        "#### Understanding the test set:"
      ],
      "metadata": {
        "id": "NIf7BgedjLZ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_test.columns)"
      ],
      "metadata": {
        "id": "A4ApkkLec2V7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Note: In the initial train set there were no missing entries in the \"Fare\" column. But, now for the submission test set, there is one missing entry in this column.\n",
        "\n",
        "#### There will be a minor change in the preprocess function to address the above issue."
      ],
      "metadata": {
        "id": "syRBMp7ilrbe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fare_median = X_train['Fare'].median()\n"
      ],
      "metadata": {
        "id": "Ppk5Fq0olrGF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_test_set(X_test, age_mean, age_std, embarked_mode, sex_mode, fare_median, scaler):\n",
        "\n",
        "    X_test = X_test.copy()\n",
        "\n",
        "    # 1. Has_cabin (safe)\n",
        "    if 'Cabin' in X_test.columns:\n",
        "        X_test['Has_cabin'] = X_test['Cabin'].apply(lambda x: 1 if isinstance(x, str) else 0)\n",
        "    else:\n",
        "        X_test['Has_cabin'] = 0\n",
        "\n",
        "    # 2. family_size\n",
        "    if 'SibSp' in X_test.columns and 'Parch' in X_test.columns:\n",
        "        X_test['family_size'] = X_test['SibSp'] + X_test['Parch'] + 1\n",
        "    else:\n",
        "        X_test['family_size'] = 1\n",
        "\n",
        "    # 3. Embarked\n",
        "    X_test['Embarked'].fillna(embarked_mode, inplace=True)\n",
        "    embarked_mapping = {'S': 0, 'C': 1, 'Q': 2}\n",
        "    X_test['Embarked'] = X_test['Embarked'].map(embarked_mapping)\n",
        "\n",
        "    # 4. Sex\n",
        "    X_test['Sex'] = X_test['Sex'].astype('object')\n",
        "    X_test['Sex'].replace(['nan', 'None', '', ' '], sex_mode, inplace=True)\n",
        "    X_test['Sex'].fillna(sex_mode, inplace=True)\n",
        "    X_test['Sex'] = X_test['Sex'].map({'female': 0, 'male': 1})\n",
        "\n",
        "    # 5. Age\n",
        "    low = int(age_mean - age_std)\n",
        "    high = int(age_mean + age_std)\n",
        "    missing_age_count = X_test['Age'].isnull().sum()\n",
        "    random_ages = np.random.randint(low, high, missing_age_count)\n",
        "    X_test.loc[X_test['Age'].isnull(), 'Age'] = random_ages\n",
        "    X_test['Age'] = X_test['Age'].astype(int)\n",
        "\n",
        "    # 6. Fare (NEW FIX)\n",
        "    X_test['Fare'].fillna(fare_median, inplace=True)\n",
        "\n",
        "    # 7. Drop unused columns\n",
        "    cols_to_drop = ['PassengerId', 'Name', 'SibSp', 'Parch', 'Ticket', 'Cabin']\n",
        "    for col in cols_to_drop:\n",
        "        if col in X_test.columns:\n",
        "            X_test.drop(columns=col, inplace=True)\n",
        "\n",
        "    # 8. Scale\n",
        "    X_test = X_test.fillna(0)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "    X_test_scaled = pd.DataFrame(X_test_scaled).fillna(0).values\n",
        "\n",
        "    return X_test_scaled\n"
      ],
      "metadata": {
        "id": "hQ4Lsp6znhrG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_processed = preprocess_test_set( X_test, age_mean, age_std, embarked_mode, sex_mode, fare_median, scaler )"
      ],
      "metadata": {
        "id": "P-TVJii2pwiI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "7mVUaw1um9hH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise  6. Prediction for test data (2 Mark)"
      ],
      "metadata": {
        "id": "c-zATg3NnlKo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.columns)\n",
        "print(X_test.columns)\n",
        "pd.DataFrame(X_test).isnull().sum()\n",
        "pd.DataFrame(X_train).isnull().sum()"
      ],
      "metadata": {
        "id": "iQ6UDzDQkgQ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_processed"
      ],
      "metadata": {
        "id": "1ZJRVgBakBR1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(X_test_processed).isnull().sum()"
      ],
      "metadata": {
        "id": "w3lURxkEj9GO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = voting_clf.predict(X_test_processed)\n",
        "y_pred\n"
      ],
      "metadata": {
        "id": "bvDpq5EHnkcB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_test.columns.tolist())"
      ],
      "metadata": {
        "id": "fs9f7B8antb2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_df = pd.DataFrame({ 'Survived': y_pred })\n",
        "pred_df"
      ],
      "metadata": {
        "id": "X6HVHUfrnFbA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}